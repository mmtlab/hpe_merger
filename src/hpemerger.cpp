/*
  _____ _ _ _                    _             _       
 |  ___(_) | |_ ___ _ __   _ __ | |_   _  __ _(_)_ __  
 | |_  | | | __/ _ \ '__| | '_ \| | | | |/ _` | | '_ \ 
 |  _| | | | ||  __/ |    | |_) | | |_| | (_| | | | | |
 |_|   |_|_|\__\___|_|    | .__/|_|\__,_|\__, |_|_| |_|
                          |_|            |___/         
# A Template for HpemergerPlugin, a Filter Plugin
# Generated by the command: C:\Program Files\MADS\usr\local\bin\mads-plugin.exe -t filter -d C:\mirrorworld\HpeMerger -i C:\Program Files\MADS\usr\local\bin HpeMerger
# Hostname: unknown
# Current working directory: C:\mirrorworld
# Creation date: 2025-06-20T10:49:12.787+0200
# NOTICE: MADS Version 1.2.2
*/
// Mandatory included headers
#include <filter.hpp>
#include <nlohmann/json.hpp>
#include <pugg/Kernel.h>
// other includes as needed here
#include <vector>
#include <array>
#include <Eigen/Dense>


// Define the name of the plugin
#ifndef PLUGIN_NAME
#define PLUGIN_NAME "hpemerger"
#endif

// Load the namespaces
using namespace std;
using json = nlohmann::json;


// Plugin class. This shall be the only part that needs to be modified,
// implementing the actual functionality
class HpemergerPlugin : public Filter<json, json> {

public:

  // Typically, no need to change this
  string kind() override { return PLUGIN_NAME; }

  // Implement the actual functionality here
  return_type load_data(json const &input, string topic = "") override {

    // Check if input has a "message" field and use it as the actual data
    json data_to_process = input;
    if (input.contains("message") && input["message"].is_object()) {
      data_to_process = input["message"];
      _is_dummy = true; 
    }

    uint64_t timestamp = 0;

    if (data_to_process.contains("typ") && data_to_process["typ"] == "FSD") {
      return return_type::error; // ignore fusion data
    }
    // store the global timestamp of the input data
    if (data_to_process.contains("ts")) {
      timestamp = data_to_process["ts"]; // get the timestamp in nanoseconds
    } else {
      // if the timestamp is not present in "ts" field, return an error (SHOULD we use the "timestamp" field instead??)
      _error = "Input data does not contain a timestamp in the 'ts' field.";
      return return_type::error;
    }

    // ignore the skeleton type (2d,3d, fusion) since the only one interesting cannot happen here

    // gets the camera index if previously set otherwise adds it to the list of cameras and returns the index
    int camera_index = get_camera_index(data_to_process["hostname"]);

    // retrieve the skeleton data just received and update the covariance matrix and joint positions
    for(const auto &[label, data] : data_to_process.items()) {
      if(data.contains("crd") && data.contains("unc")){
        
        // Validate that crd and unc are arrays with correct size
        if (!data["crd"].is_array() || !data["unc"].is_array()) {
          continue;
        }

        if (data["crd"].size() != 3 || data["unc"].size() != 6) {
          continue;
        }

        // Check if all coordinate values are valid numbers (not empty strings)
        bool crd_valid = true;
        for (size_t i = 0; i < 3; ++i) {
          if (!data["crd"][i].is_number()) {
            crd_valid = false;
            break;
          }
        }

        // Check if all covariance values are valid numbers (not empty strings)
        bool unc_valid = true;
        for (size_t i = 0; i < 6; ++i) {
          if (!data["unc"][i].is_number()) {
            unc_valid = false;
            break;
          }
        }

        if (!crd_valid || !unc_valid) {
          continue;
        }

        // At this point, we have valid data
        if (keypoints_map_string2int.find(label) == keypoints_map_string2int.end()) {
          continue;
        }

        int joint_index = keypoints_map_string2int[label]; // joint index

        _positions[joint_index][camera_index] = Eigen::Vector3d(data["crd"][0], data["crd"][1], data["crd"][2]);

        Eigen::Matrix3d covariance_matrix = Eigen::Matrix3d::Zero();
        covariance_matrix << data["unc"][0], data["unc"][3], data["unc"][4],
                             data["unc"][3], data["unc"][1], data["unc"][5],
                             data["unc"][4], data["unc"][5], data["unc"][2];
        _covariances[joint_index][camera_index] = covariance_matrix;

        _times[joint_index][camera_index] = timestamp; // store the timestamp of the joint
      }  
    }

    return return_type::success;
  }

  // We calculate the average of the last N values for each key and store it
  // into the output json object
  return_type process(json &out) override {
    out.clear();
    
    int64_t timestamp;
    if (!_is_dummy) {
      // Current timestamp in nanoseconds
      // For LIVE processing, use system time:
      auto now = std::chrono::system_clock::now();
      timestamp = std::chrono::duration_cast<std::chrono::nanoseconds>(now.time_since_epoch()).count();
    }
    else {
      // For RECORDED data processing, use the maximum timestamp from the data:
      // Find the maximum timestamp in _times across all joints and cameras
      uint64_t max_time = 0;
      for (size_t joint = 0; joint < _times.size(); ++joint) {
        for (size_t cam = 0; cam < _times[joint].size(); ++cam) {
          if (_times[joint][cam] > max_time) {
            max_time = _times[joint][cam];
          }
        }
      }
      
      // Add a random delay between 1 and 30 ms (in nanoseconds) to simulate processing
      timestamp = max_time + 1000000 + (rand() % 29000000);
    }

    // load the data as necessary and set the fields of the json out variable

    // predict the current positions of the joints based on the previous positions and velocities
    std::vector<Eigen::Vector3d> merged_positions_prev(_merged_positions.size());
    std::vector<Eigen::Matrix3d> merged_covariances_prev(_merged_positions.size()); // please note that this is already weighted and inverted
    std::vector<Eigen::Vector3d> prior_positions(_merged_positions.size()); // this is the PRIOR for the fusion
    std::vector<Eigen::Matrix3d> prior_covariances_inv(_merged_positions.size());
    std::vector<double> prior_weights(_merged_positions.size());

    // get the time weight normalization factor from the parameters
    double time_const = _params["time_weight_normalization"].get<double>();

    // Compute the current positions, covariances and weights based on the merged positions, covariances and velocities
    double merged_time_diff;

    //computes the weights for each joint based on the time difference between the current timestamp and the timestamp of the joint
    std::vector<std::vector<double>> weights(_positions.size(), std::vector<double>(_positions[0].size(), 0.0));
    for (size_t joint = 0; joint < _positions.size(); ++joint) {

      // Calculate the prior weight based on the time difference
      merged_time_diff = (static_cast<int64_t>(timestamp) - static_cast<int64_t>(_merged_times[joint])) / 1e9; // time difference between the current timestamp and the merged timestamp IN SECONDS
      prior_weights[joint] = exp(-((merged_time_diff)*(merged_time_diff)) / (time_const * time_const)); // weight based on the time difference
      
      // Calculate the weights for each camera based on the time difference
      for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
        double time_diff = (static_cast<int64_t>(timestamp) - static_cast<int64_t>(_times[joint][cam])) / 1e9; // time difference between the current timestamp and the joint timestamp IN SECONDS
        
        // weight is computed as an exponential based on the time difference (e^(-time_diff^2 / tau^2))
        weights[joint][cam] = exp(-((time_diff)*(time_diff)) / (time_const * time_const));  
      
      }
      
      //normalize the weights for each joint and the prior weight
      double sum_weights = std::accumulate(weights[joint].begin(), weights[joint].end(), 0.0);
      sum_weights += prior_weights[joint]; // add also the prior weight
      if (sum_weights > 0) {
        for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
          weights[joint][cam] /= sum_weights; // normalize the weights
        }
        prior_weights[joint] /= sum_weights; // normalize the prior weight
      } 
      
      // compute the prior positions and covariances with normalized weights
      merged_positions_prev[joint] = _merged_positions[joint]; // stores for the velocity computation at the end
      prior_positions[joint] = merged_positions_prev[joint] + _velocities[joint]*(merged_time_diff); // assuming _times[joint] is in m/ns since the timestamp is in ns
      if (_merged_covariances[joint].determinant() != 0) {
        merged_covariances_prev[joint] = _merged_covariances[joint]; // store the previous merged covariance for the velocity computation at the end
        prior_covariances_inv[joint] = merged_covariances_prev[joint] + (merged_time_diff * merged_time_diff) * _velocities_covariances[joint]; // propagate the covariance based on the velocity and time difference
        prior_covariances_inv[joint] = (prior_covariances_inv[joint]).inverse()*prior_weights[joint]; // update the covariance based on the weight (inverted for computational efficiency)
      } else {
        prior_covariances_inv[joint] = Eigen::Matrix3d::Zero(); // if the covariance is singular, set it to zero
      }
      //DEBUG ONLY: set prior to zero  (unrelevant)
      // prior_covariances_inv[joint] = Eigen::Matrix3d::Zero(); 

    }

    // compute the weighted covariance matrices for each joint and camera AND INVERTS THEM!
    std::vector<std::vector<Eigen::Matrix3d>> weighted_covariances_inv(_covariances.size()); // _covariances[j][i] is the covariance matrix of the j-th joint of the i-th camera times weights
    for (size_t joint = 0; joint < _covariances.size(); ++joint) {
      weighted_covariances_inv[joint].resize(_covariances[joint].size());
      for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
        if (_covariances[joint][cam].determinant() != 0 ){
          weighted_covariances_inv[joint][cam] = (_covariances[joint][cam]).inverse() * weights[joint][cam]; // multiply the covariance matrix by the weight (inverted for computational efficiency)
        }  else {
          // if the covariance matrix is singular, set it to zero
          weighted_covariances_inv[joint][cam] = Eigen::Matrix3d::Zero();
        }
      }
    }
    
    //compute the merged positions and covariances for each joint from the weighted covariances and the positions
    for (size_t joint = 0; joint < _positions.size(); ++joint) {
      _merged_positions[joint] = Eigen::Vector3d::Zero();
      _merged_covariances[joint] = Eigen::Matrix3d::Zero();
      _camera_used[joint] = 0; // reset the camera used for the joint

      for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
        if ((_covariances[joint][cam](0,0) <= 0) || (_covariances[joint][cam](1,1) <= 0) || (_covariances[joint][cam](2,2) <= 0)){
           // check if the joint has a valid covariance (no null first element, no negative values)
        }else{
          _merged_covariances[joint] += weighted_covariances_inv[joint][cam]; // merge the covariances using the inverse
        }
      }
      
      //adds the prior positions weighted by the weights to the merged position
      _merged_covariances[joint] += prior_covariances_inv[joint]; // add the current covariance to the merged covariance
      _merged_covariances[joint] = _merged_covariances[joint].inverse(); // invert the merged covariance matrix

      // merge the positions using the weights and the covariances
      _merged_positions[joint] = Eigen::Vector3d::Zero(); // reset the merged position for the joint
      for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
        if ((_covariances[joint][cam](0,0) <= 0) || (_covariances[joint][cam](1,1) <= 0) || (_covariances[joint][cam](2,2) <= 0)) {
          // check if the joint has a valid covariance (no null first element, no negative values)
        } else {
            _merged_positions[joint] += weighted_covariances_inv[joint][cam] * _positions[joint][cam];
            _camera_used[joint] += 1; // increment the camera used for the joint
        }
      }
      
      _merged_positions[joint] += prior_covariances_inv[joint] * prior_positions[joint]; // add the current position to the merged position
      _merged_positions[joint] = _merged_covariances[joint] * _merged_positions[joint]; // multiply the merged position by the merged covariance matrix
    }

    //computes the joint velocities based on the previous positions and the current positions for the next iteration
    for (size_t joint = 0; joint < _positions.size(); ++joint) {

      double dt = (timestamp - _merged_times[joint]) / 1e9; // time difference between the current timestamp and the merged timestamp IN SECONDS  
      
      _velocities[joint] = (_merged_positions[joint] - merged_positions_prev[joint]) / dt; // compute the velocity as the difference between the current position and the previous position divided by the time difference
      _velocities_covariances[joint] = (1/(dt * dt)) * (_merged_covariances[joint] + merged_covariances_prev[joint]); // compute the velocity covariance as the sum of the merged covariance and the current covariance divided by the time difference
      
      _merged_times[joint] = timestamp;
    }

    //TODO: Pubblicare i dati della fusione ed aggiornare le posizioni, le velocitÃ  e covarianze dei giunti della fusione
    // Fill the output json object with the merged positions and covariances
    out["ts"] = timestamp; // set the timestamp of the output data
    out["typ"] = "FSD"; // set the type of the output data to fusion

    for (size_t joint = 0; joint < _merged_positions.size(); ++joint) {
      string joint_name = keypoints_map_int2string[joint]; // get the joint name from the map
      out[joint_name]["ncm"] = _camera_used[joint]; 
      out[joint_name]["crd"] = { _merged_positions[joint](0), _merged_positions[joint](1), _merged_positions[joint](2) };
      out[joint_name]["unc"] = { _merged_covariances[joint](0,0), _merged_covariances[joint](1,1), _merged_covariances[joint](2,2),
                            _merged_covariances[joint](0,1), _merged_covariances[joint](0,2), _merged_covariances[joint](1,2) };
    }
   
    // This sets the agent_id field in the output json object, only when it is
    // not empty
    if (!_agent_id.empty()) out["agent_id"] = _agent_id;
    return return_type::success;
  }
  
  void set_params(void const *params) override {
    // Call the parent class method to set the common parameters 
    // (e.g. agent_id, etc.)
    Filter::set_params(params);

    // then merge the defaults with the actually provided parameters
    // params needs to be cast to json
    _params.merge_patch(*(json *)params);

    // provide sensible defaults for the parameters by setting e.g.
    if (_params.contains("time_weight_normalization") == false){
      _params["time_weight_normalization"] = 1.0; // default time weight normalization factor in seconds
    }

    _params["joint_map"] = { "NOS_","NEC_","SHOR","ELBR","WRIR","SHOL","ELBL","WRIL","HIPR","KNER","ANKR","HIPL","KNEL","ANKL","EYEL","EYER","EARR","EARL"}; // default joint map for HPE
    // creates two maps to faciliate indexing the joints by name and index
    for (size_t i = 0; i < _params["joint_map"].size(); ++i) {
      keypoints_map_string2int[_params["joint_map"][i]] = i;
      keypoints_map_int2string[i] = _params["joint_map"][i];
    }

    // Current timestamp in nanoseconds
    auto now = std::chrono::system_clock::now();
    int64_t timestamp = std::chrono::duration_cast<std::chrono::nanoseconds>(now.time_since_epoch()).count();

    // initialize the internal vectors based on the number of cameras
    size_t num_joints = _params["joint_map"].size();
    _positions.resize(num_joints);
    _covariances.resize(num_joints);
    _times.resize(num_joints);
    _velocities.resize(num_joints, Eigen::Vector3d::Zero());
    _velocities_covariances.resize(num_joints, Eigen::Matrix3d::Identity() * 2500.0);
    _merged_positions.resize(num_joints, Eigen::Vector3d::Zero());
    _merged_covariances.resize(num_joints, Eigen::Matrix3d::Identity() * 2500.0);
    _merged_times.resize(num_joints, 0);
    _camera_used.resize(num_joints, 0);

    for (size_t joint = 0; joint < num_joints; ++joint) {
      _merged_times[joint] = timestamp; // set the merged time to the current timestamp
    }
  }

  // gets the camera index if previously set otherwise adds it to the list of cameras and returns the index (resizes the internal vectors to accommodate the new camera)
  int get_camera_index(string const &camera_name) {
    if (_cameras.find(camera_name) == _cameras.end()) {
      // camera not found, add it
      int index = _cameras.size();
      _cameras[camera_name] = index;

      //also resize the internal vectors to accommodate the new camera
      for (size_t joint = 0; joint < _positions.size(); ++joint) {
        _positions[joint].resize(_positions[joint].size() + 1);
        _covariances[joint].resize(_covariances[joint].size() + 1);
        _times[joint].resize(_times[joint].size() + 1);
        _velocities.resize(_velocities.size() + 1);
        _positions[joint][index] = Eigen::Vector3d::Zero(); // initialize the position to zero
        _covariances[joint][index] = Eigen::Matrix3d::Zero(); // initialize the covariance matrix to zero
        _velocities[joint] = Eigen::Vector3d::Zero(); // initialize the velocity to zero
      }

      return index;
    } else {
      // camera found, return its index
      return _cameras[camera_name];
    }
  }

  // Implement this method if you want to provide additional information
  map<string, string> info() override { 
    // return a map of stringswith additional information about the plugin
    // it is used to print the information about the plugin when it is loaded
    // by the agent
    return {}; 
  };

private:

  // Set if data are received from a dummy source (with "message" field). If dummy, we need to simulate the current timestamp adding a delay to the maximum timestamp received.
  bool _is_dummy = false;

  // Maps the joint names to their indices
  map<string, int> keypoints_map_string2int;
  map<int, string> keypoints_map_int2string;
  //  = {
  //   {"NOS_",1}, {"NEC_",2},  {"SHOR",3}, {"ELBR",4}, {"WRIR",5},
  //   {"SHOL",5},  {"ELBL",6},  {"WRIL",7},  {"HIPR",8}, {"KNER",9},
  //   {"ANKR",10}, {"HIPL",11}, {"KNEL",12}, {"ANKL",13}, {"EYER",14},
  //   {"EYEL",15}, {"EARR",16}, {"EARL",17}};

  // Define the fields that are used to store internal resources
  std::vector<std::vector<Eigen::Vector3d>> _positions; // _positions[j][i] is the position (x,y,z) of the j-th joint of the i-th camera.
  std::vector<std::vector<Eigen::Matrix3d>> _covariances;  // _covariances[j][i] is the covariance matrix of the j-th joint of the i-th camera.
  std::vector<std::vector<uint64_t>> _times; // _times[j][i] is the time of the j-th joint of the i-th camera, computed from the previous prediction step.
  std::vector<Eigen::Vector3d> _velocities; // _velocities[j] is the velocity (x,y,z) of the j-th joint, computed from the previous prediction step. 
  std::vector<Eigen::Matrix3d> _velocities_covariances; // _velocities[j] is the velocity (x,y,z) of the j-th joint, computed from the previous prediction step. 
  std::vector<Eigen::Vector3d> _merged_positions; // _merged_positions[j] is the position (x,y,z) of the j-th joint, computed from the previous prediction step of the merged data.
  std::vector<Eigen::Matrix3d> _merged_covariances; // _merged_covariances[j] is the covariance matrix of the j-th joint, computed from the previous prediction step of the merged data 
  std::vector<uint64_t> _merged_times; // _merged_times[j] is the time of the j-th joint, computed from the previous prediction step of the merged data
  std::vector<int> _camera_used; // is the number of camera used to merge the j-th joint 

  //lists the cameras that are transimitting data
  map<string, int> _cameras; // maps the camera name to its index  if previosly set
};


/*
  ____  _             _             _      _
 |  _ \| |_   _  __ _(_)_ __     __| |_ __(_)_   _____ _ __
 | |_) | | | | |/ _` | | '_ \   / _` | '__| \ \ / / _ \ '__|
 |  __/| | |_| | (_| | | | | | | (_| | |  | |\ V /  __/ |
 |_|   |_|\__,_|\__, |_|_| |_|  \__,_|_|  |_| \_/ \___|_|
                |___/
Enable the class as plugin
*/
INSTALL_FILTER_DRIVER(HpemergerPlugin, json, json);


/*
                  _       
  _ __ ___   __ _(_)_ __  
 | '_ ` _ \ / _` | | '_ \ 
 | | | | | | (_| | | | | |
 |_| |_| |_|\__,_|_|_| |_|
                          
*/

int main(int argc, char const *argv[])
{
  HpemergerPlugin plugin;
  json params;
  json input, output;

  // Set example values to params
  params["test"] = "value";

  // Set the parameters
  plugin.set_params(&params);

  // Set input data
  input["data"] = {
    {"AX", 1},
    {"AY", 2},
    {"AZ", 3}
  };

  // Set input data
  plugin.load_data(input);
  cout << "Input: " << input.dump(2) << endl;

  // Process data
  plugin.process(output);
  cout << "Output: " << output.dump(2) << endl;


  return 0;
}

