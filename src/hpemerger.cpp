/*
  _____ _ _ _                    _             _       
 |  ___(_) | |_ ___ _ __   _ __ | |_   _  __ _(_)_ __  
 | |_  | | | __/ _ \ '__| | '_ \| | | | |/ _` | | '_ \ 
 |  _| | | | ||  __/ |    | |_) | | |_| | (_| | | | | |
 |_|   |_|_|\__\___|_|    | .__/|_|\__,_|\__, |_|_| |_|
                          |_|            |___/         
# A Template for HpemergerPlugin, a Filter Plugin
# Generated by the command: C:\Program Files\MADS\usr\local\bin\mads-plugin.exe -t filter -d C:\mirrorworld\HpeMerger -i C:\Program Files\MADS\usr\local\bin HpeMerger
# Hostname: unknown
# Current working directory: C:\mirrorworld
# Creation date: 2025-06-20T10:49:12.787+0200
# NOTICE: MADS Version 1.2.2
*/

// Run this plugin with --dont-block enable to avoid blocking the process
// Con -p set the sampling period in ms
// mads-filter hpemerger.plugin --dont-block -p50 

// Mandatory included headers
#include <filter.hpp>
#include <nlohmann/json.hpp>
#include <pugg/Kernel.h>
// other includes as needed here
#include <vector>
#include <array>
#include <Eigen/Dense>


// Define the name of the plugin
#ifndef PLUGIN_NAME
#define PLUGIN_NAME "hpemerger"
#endif

// Load the namespaces
using namespace std;
using json = nlohmann::json;


// Plugin class. This shall be the only part that needs to be modified,
// implementing the actual functionality
class HpemergerPlugin : public Filter<json, json> {

public:

  // Typically, no need to change this
  string kind() override { return PLUGIN_NAME; }

  // Implement the actual functionality here
  return_type load_data(json const &input, string topic = "") override {
    // load data from input json object but if the UNCERTAINTY is missing or invalid, skip the joint, do not update its position and covariance
    // if the covariance matrix is null, its determinat is null or the diagonal elements are negative, skip the joint

    // Check if input has a "message" field and use it as the actual data
    json data_to_process = input;
    if (input.contains("message") && input["message"].is_object()) {
      data_to_process = input["message"];
      _is_dummy = true; 
    }

    uint64_t timestamp = 0;

    if (data_to_process.contains("typ") && data_to_process["typ"] == "FSD") {
      return return_type::retry; // ignore fusion data
    }
    // store the global timestamp of the input data
    if (data_to_process.contains("ts")) {
      timestamp = data_to_process["ts"]; // get the timestamp in nanoseconds
    } else {
      // if the timestamp is not present in "ts" field, return an error (SHOULD we use the "timestamp" field instead??)
      _error = "Input data does not contain a timestamp in the 'ts' field.";
      return return_type::retry;
    }

    // ignore the skeleton type (2d,3d, fusion) since the only one interesting cannot happen here

    // gets the camera index if previously set otherwise adds it to the list of cameras and returns the index
    int camera_index = get_camera_index(data_to_process["hostname"]);

    // Check if input has a "message" field and use it as the actual data
    json data_joints = input;
    if (input.contains("joints") && input["joints"].is_object()) {
      data_joints = input["joints"];
    }

    // retrieve the skeleton data just received and update the covariance matrix and joint positions
    for(const auto &[label, data] : data_joints.items()) {
      if(data.contains("crd") && data.contains("unc")){
        
        // Validate that crd and unc are arrays with correct size
        if (!data["crd"].is_array() || !data["unc"].is_array()) {
          continue;
        }

        if (data["crd"].size() != 3 || data["unc"].size() != 6) {
          continue;
        }

        // Check if all coordinate values are valid numbers (not empty strings)
        bool crd_valid = true;
        for (size_t i = 0; i < 3; ++i) {
          if (!data["crd"][i].is_number()) {
            crd_valid = false;
            break;
          }
        }

        // Check if all covariance values are valid numbers (not empty strings)
        bool unc_valid = true;
        for (size_t i = 0; i < 6; ++i) {
          if (!data["unc"][i].is_number()) {
            unc_valid = false;
            break;
          }
        }

        if (!crd_valid || !unc_valid) {
          continue;
        }

        // At this point, we have valid data
        if (keypoints_map_string2int.find(label) == keypoints_map_string2int.end()) {
          continue;
        }

        int joint_index = keypoints_map_string2int[label]; // joint index

        
        Eigen::Matrix3d covariance_matrix = Eigen::Matrix3d::Zero();
        covariance_matrix << data["unc"][0], data["unc"][3], data["unc"][4],
                             data["unc"][3], data["unc"][1], data["unc"][5],
                             data["unc"][4], data["unc"][5], data["unc"][2];

        // check if the covariance matrix is valid so we don't need to do it later
        if ((covariance_matrix(0,0) <= 0) || (covariance_matrix(1,1) <= 0) || (covariance_matrix(2,2) <= 0) || (covariance_matrix.determinant() == 0)) {
          // check if the joint has a valid covariance (no null first element, no negative values)
          //DEBUG ONLY
          cout << "Joint " << joint_index << " cam " << camera_index << " covariance invalid " << endl;
          continue;
        } else {

          // updates the internal storage of positions and covariances for the joint and camera (should not do if anything is invalid)
          _positions[joint_index][camera_index] = Eigen::Vector3d(data["crd"][0], data["crd"][1], data["crd"][2]);
          _covariances[joint_index][camera_index] = covariance_matrix;
          _times[joint_index][camera_index] = timestamp; // store the timestamp of the joint

          //DEBUG ONLY
          //_covariances[joint_index][camera_index]= Eigen::Matrix3d::Identity()*100; // set a fixed covariance for testing
        }

      }  
    }

    return return_type::success;
  }

  // We calculate the average of the last N values for each key and store it
  // into the output json object
  return_type process(json &out) override {
    out.clear();
    
    int64_t timestamp;
    if (!_is_dummy) {
      // Current timestamp in nanoseconds
      // For LIVE processing, use system time:
      auto now = std::chrono::system_clock::now();
      timestamp = std::chrono::duration_cast<std::chrono::nanoseconds>(now.time_since_epoch()).count();
    }
    else {
      // For RECORDED data processing, use the maximum timestamp from the data:
      // Find the maximum timestamp in _times across all joints and cameras
      uint64_t max_time = 0;
      for (size_t joint = 0; joint < _times.size(); ++joint) {
        for (size_t cam = 0; cam < _times[joint].size(); ++cam) {
          if (_times[joint][cam] > max_time) {
            max_time = _times[joint][cam];
          }
        }
      }
      
      // Add a random delay between 1 and 30 ms (in nanoseconds) to simulate processing
      timestamp = max_time + 1000000 + (rand() % 29000000);
    }

    //since we always compute the merge at this point, the time step is computed only once
    double dt = (timestamp - _last_merge_time) * 1e-9; // time difference between the current timestamp and the merged timestamp IN SECONDS 

    // load the data as necessary and set the fields of the json out variable

    // predict the current positions of the joints based on the previous positions and velocities
    std::vector<Eigen::Vector3d> merged_positions_prev(_merged_positions.size());
    std::vector<Eigen::Matrix3d> merged_covariances_prev(_merged_positions.size()); // covariance matrices at previous time step
    std::vector<Eigen::Vector3d> prior_positions(_merged_positions.size()); // this is the PRIOR for the fusion
    std::vector<Eigen::Matrix3d> prior_covariances(_merged_positions.size());
    std::vector<double> prior_weights(_merged_positions.size(), 0.0); // weights for the prior positions (is the prior_weight divided by the normalization for each joint)
    
    // get the time weight normalization factor from the parameters
    double time_const = _params["time_weight_normalization"].get<double>();
    // Calculate the prior weight based on the time difference
    double prior_weight=0.0; // weight for the prior position (just one!)  NOTE: we compute the prior ALWAYS even if not used for fusion later (weight=0)
    if (_params["enable_prior"].get<bool>() == true) {
      prior_weight = exp(-((dt)*(dt)) / (time_const * time_const)); // weight based on the time difference
    }

    //prepares the arrays for the fusion merge
    std::vector<std::vector<Eigen::Vector3d>> positions=_positions; // _positions[j][i] is the position (x,y,z) in mm of the j-th joint of the i-th camera
    std::vector<std::vector<Eigen::Matrix3d>> covariances=_covariances;  // _covariances[j][i] is the covariance matrix in mm² of the j-th joint of the i-th camera
    std::vector<std::vector<double>> weights(positions.size(), std::vector<double>(positions[0].size(), 0.0));

    // Calculate the weights for each camera based on the time difference (e^(-time_diff^2 / tau^2))
    for (size_t joint = 0; joint < _positions.size(); ++joint) {
      for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
        double time_diff = (static_cast<int64_t>(timestamp) - static_cast<int64_t>(_times[joint][cam])) * 1e-9; // time difference between the current timestamp and the joint timestamp IN SECONDS
        weights[joint][cam] = exp(-((time_diff)*(time_diff)) / (time_const * time_const));  
      }
    }       

    // compute the prior positions and covariances for each joint based on THE PREVIOUS merged positions and velocities (stored in _merged_positions and _velocities)
    for (size_t joint = 0; joint < _positions.size(); ++joint) {
      merged_positions_prev[joint] = _merged_positions[joint]; // stores for the velocity computation at the end
      merged_covariances_prev[joint] = _merged_covariances[joint]; // store the previous merged covariance for the velocity computation at the end
      prior_positions[joint] = merged_positions_prev[joint] + _velocities[joint]*(dt); // positions in mm, velocity in mm/s, merged_time_diff in s
      if (_merged_covariances[joint].determinant() != 0) {
          prior_covariances[joint] = merged_covariances_prev[joint] + (dt * dt) * _velocities_covariances[joint]; // propagate the covariance based on the velocity and time difference
          prior_weights[joint] = prior_weight; // set the prior weight for the joint
      } else {
        //DEBUG ONLY should never happen
        cout << "Joint " << joint << " merged covariance null " << endl;
        prior_weights[joint] = 0; // if the covariance is singular, set it to zero
      }
    }

    //adds the prior to the arrays for the fusion merge
    for (size_t joint = 0; joint < positions.size(); ++joint) {
      positions[joint].push_back(prior_positions[joint]);
      covariances[joint].push_back(prior_covariances[joint]);
      weights[joint].push_back(prior_weights[joint]);
    }

    int valid_ok = fuse_positions(positions, covariances, weights, _merged_positions, _merged_covariances); //use the internal method to fuse the positions

    if(valid_ok != 0){
      // if the fusion failed for some reason, return an error
      cout << "Fusion of positions failed due to zero weights data." << endl;
      return return_type::retry;
    }
    //computes the joint velocities based on the previous positions and the current positions for the next iteration
    for (size_t joint = 0; joint < _merged_positions.size(); ++joint) {
      _velocities[joint] = (_merged_positions[joint] - merged_positions_prev[joint]) / dt; // compute the velocity as the difference between the current position and the previous position divided by the time difference
      _velocities_covariances[joint] = (1/(dt * dt)) * (_merged_covariances[joint] + merged_covariances_prev[joint]); // compute the velocity covariance as the sum of the merged covariance and the current covariance divided by the time difference
    }

    //update the last merge time
    _last_merge_time = timestamp;

    // Fill the output json object with the merged positions and covariances
    out["ts"] = timestamp; // set the timestamp of the output data
    out["typ"] = "FSD"; // set the type of the output data to fusion

    for (size_t joint = 0; joint < _merged_positions.size(); ++joint) {
      string joint_name = keypoints_map_int2string[joint]; // get the joint name from the map
      out["joints"][joint_name]["ncm"] = _camera_used[joint]; 
      out["joints"][joint_name]["crd"] = { _merged_positions[joint](0), _merged_positions[joint](1), _merged_positions[joint](2) };
      out["joints"][joint_name]["unc"] = { _merged_covariances[joint](0,0), _merged_covariances[joint](1,1), _merged_covariances[joint](2,2),
                            _merged_covariances[joint](0,1), _merged_covariances[joint](0,2), _merged_covariances[joint](1,2) };
      
      // Debug
      out["joints"][joint_name]["prior_crd"] = { prior_positions[joint](0), prior_positions[joint](1), prior_positions[joint](2) };
      //out["joints"][joint_name]["prior_unc_inv"] = { weighted_prior_covariances_inv[joint](0,0), weighted_prior_covariances_inv[joint](1,1), weighted_prior_covariances_inv[joint](2,2),
      //                                               weighted_prior_covariances_inv[joint](0,1), weighted_prior_covariances_inv[joint](0,2), weighted_prior_covariances_inv[joint](1,2) };
      //auto prior_covariances = weighted_prior_covariances_inv[joint].inverse();
      out["joints"][joint_name]["prior_unc"] = { prior_covariances[joint](0,0), prior_covariances[joint](1,1), prior_covariances[joint](2,2),
                            prior_covariances[joint](0,1), prior_covariances[joint](0,2), prior_covariances[joint](1,2) };
                     
    }
   
    // This sets the agent_id field in the output json object, only when it is
    // not empty
    if (!_agent_id.empty()) out["agent_id"] = _agent_id;
    return return_type::success;
  }
  
  void set_params(void const *params) override {
    // Call the parent class method to set the common parameters 
    // (e.g. agent_id, etc.)
    Filter::set_params(params);

    // then merge the defaults with the actually provided parameters
    // params needs to be cast to json
    _params.merge_patch(*(json *)params);

    // provide sensible defaults for the parameters by setting e.g.
    if (_params.contains("time_weight_normalization") == false){
      _params["time_weight_normalization"] = 1.0; // default time weight normalization factor in seconds
    }

    if (_params.contains("enable_prior") == false){
      _params["enable_prior"] = false; // default enable prior
    }

    _params["joint_map"] = { "NOS_","NEC_","SHOR","ELBR","WRIR","SHOL","ELBL","WRIL","HIPR","KNER","ANKR","HIPL","KNEL","ANKL","EYEL","EYER","EARR","EARL"}; // default joint map for HPE
    // creates two maps to faciliate indexing the joints by name and index
    for (size_t i = 0; i < _params["joint_map"].size(); ++i) {
      keypoints_map_string2int[_params["joint_map"][i]] = i;
      keypoints_map_int2string[i] = _params["joint_map"][i];
    }

    // Current timestamp in nanoseconds
    auto now = std::chrono::system_clock::now();
    int64_t timestamp = std::chrono::duration_cast<std::chrono::nanoseconds>(now.time_since_epoch()).count();

    // initialize the internal vectors based on the number of cameras
    size_t num_joints = _params["joint_map"].size();
    _positions.resize(num_joints);
    _covariances.resize(num_joints);
    _times.resize(num_joints);
    _velocities.resize(num_joints, Eigen::Vector3d::Zero());
    _velocities_covariances.resize(num_joints, Eigen::Matrix3d::Identity() * 2500.0); // initial uncertainty: 2500 mm²/s² (~50 mm/s std dev)
    _merged_positions.resize(num_joints, Eigen::Vector3d::Zero());
    _merged_covariances.resize(num_joints, Eigen::Matrix3d::Identity() * 250000.0); // initial uncertainty: 250000 mm² (~500 mm std dev)
    _last_merge_time=0; //time of the last merge computation (same for all joints)
    _camera_used.resize(num_joints, 0);

  }


  // fuses positions based on their covariance matrices and weights, with a discrepance limit to discard outliers
  int fuse_positions(
    const std::vector<std::vector<Eigen::Vector3d>> positions, // positions[j][i] is the position (x,y,z) in mm of the j-th joint of the i-th camera
    const std::vector<std::vector<Eigen::Matrix3d>> covariances,  // covariances[j][i] is the covariance matrix in mm² of the j-th joint of the i-th camera
    std::vector<std::vector<double>> weights, // weights[j][i] is the weight of the j-th joint of the i-th camera
    std::vector<Eigen::Vector3d> &fused_positions, // output fused position in mm of each j-th joint
    std::vector<Eigen::Matrix3d> &fused_covariances, // output fused covariance in mm² of each j-th joint
    double discrepance_limit = 300000.0 // in mm
  ) {
    // implement the fusion of positions based on their covariance matrices and weights
    // return 0 if successful, -1 if no valid positions were provided

      //cycles through the joints
      for (size_t joint = 0; joint < positions.size(); ++joint) {

        //excludes positions that are too far from the left-out average position
        if(positions[0].size()>1){ //only if more than one position is available
          //compute the left-out average position for the joint
          std::vector<Eigen::Vector3d> leftout_positions;
          for (size_t cam = 0; cam < positions[joint].size(); ++cam) {
            //left out the cam-th position
            Eigen::Vector3d leftout_avg = Eigen::Vector3d::Zero();
            for (size_t cam2 = 0; cam2 < positions[joint].size(); ++cam2) {
              if (cam2 != cam) {
                leftout_avg += positions[joint][cam2]/(positions[joint].size() - 1);
              }
            }
            leftout_positions.push_back(leftout_avg);
          }

          //now excludes the positions that are too far from the left-out average position
          for (size_t cam = 0; cam < positions[joint].size(); ++cam) {
            double distance = (positions[joint][cam] - leftout_positions[cam]).norm();
            if (distance > discrepance_limit) {
              // exclude this position by setting its weight to zero
              weights[joint][cam] = 0.0;
            }else{
              weights[joint][cam] *= (1.0 - (distance / discrepance_limit)*(distance / discrepance_limit)); // decrease the weight based on the distance
            }
          }
        }

        //normalize the weights for each joint and the prior weight
        double sum_weights = std::accumulate(weights[joint].begin(), weights[joint].end(), 0.0);
        if (sum_weights <= 0) {
          return -1; // no valid positions provided
        }
        for (size_t cam = 0; cam < _positions[joint].size(); ++cam) {
          weights[joint][cam] /= sum_weights; // normalize the weights
          //DEBUG ONLY
          // weights[joint][cam] = 1;
        }
         
        // adds the weighted covariance matrices for each joint and camera AND INVERTS THEM!
        Eigen::Vector3d fused_j_position = Eigen::Vector3d::Zero();
        Eigen::Matrix3d fused_j_covariance = Eigen::Matrix3d::Zero();
        std::vector<Eigen::Matrix3d> weighted_covariances_inv(covariances[joint].size()); 

        for (size_t cam = 0; cam < positions[joint].size(); ++cam) {
          weighted_covariances_inv[cam] = (covariances[joint][cam]).inverse() * weights[joint][cam]; // information matrix scaled by weight: lower weight = less contribution to fusion
          fused_j_covariance += weighted_covariances_inv[cam]; // merge the covariances using the inverse
          fused_j_position +=  weighted_covariances_inv[cam] * positions[joint][cam];
          if(joint == 7){ //DEBUG ONLY
            cout << "J" << joint << "C" << cam << ": weight " << weights[joint][cam] << " cov: " << endl << covariances[joint][cam](0,0) << "|" << covariances[joint][cam](1,1) << "|" << covariances[joint][cam](2,2) << endl;
          }
        }
        fused_j_covariance = fused_j_covariance.inverse(); // revert the merged covariance matrix
        fused_j_position = fused_j_covariance * fused_j_position; // multiply the merged position by the merged covariance matrix (to normalize the positions' weights)
        
        cout << "FUSED: weight " << sum_weights << " cov: " << endl << fused_j_covariance(0,0) << "|" << fused_j_covariance(1,1) << "|" << fused_j_covariance(2,2) << endl;

        // update the output fused positions and covariances
        fused_positions[joint] = fused_j_position;
        fused_covariances[joint] = fused_j_covariance;
      } 

    return 0; // placeholder
  }


  // gets the camera index if previously set otherwise adds it to the list of cameras and returns the index (resizes the internal vectors to accommodate the new camera)
  int get_camera_index(string const &camera_name) {
    if (_cameras.find(camera_name) == _cameras.end()) {
      // camera not found, add it
      int index = _cameras.size();
      _cameras[camera_name] = index;

      //also resize the internal vectors to accommodate the new camera
      for (size_t joint = 0; joint < _positions.size(); ++joint) {
        _positions[joint].resize(_positions[joint].size() + 1);
        _covariances[joint].resize(_covariances[joint].size() + 1);
        _times[joint].resize(_times[joint].size() + 1);

        _positions[joint][index] = Eigen::Vector3d::Zero(); // initialize the position to zero
        _covariances[joint][index] = Eigen::Matrix3d::Identity()*250000.0; // initialize the covariance matrix to a big identity matrix (250000 mm² ~ 500 mm std dev)
        _times[joint][index] = 0; // initialize the time to zero

        // DEBUG ONLY
        // cout << "Added new camera: " << camera_name << " with index " << index << endl;
        // cout << "Resized internal vectors for joint " << joint << " to size " << _positions[joint].size() << endl;
      }

      return index;
    } else {
      // camera found, return its index
      return _cameras[camera_name];
    }
  }

  // Implement this method if you want to provide additional information
  map<string, string> info() override { 
    // return a map of stringswith additional information about the plugin
    // it is used to print the information about the plugin when it is loaded
    // by the agentFC
    return {}; 
  };

private:

  // Set if data are received from a dummy source (with "message" field). If dummy, we need to simulate the current timestamp adding a delay to the maximum timestamp received.
  bool _is_dummy = false;

  // Maps the joint names to their indices
  map<string, int> keypoints_map_string2int;
  map<int, string> keypoints_map_int2string;
  //  = {
  //   {"NOS_",1}, {"NEC_",2},  {"SHOR",3}, {"ELBR",4}, {"WRIR",5},
  //   {"SHOL",5},  {"ELBL",6},  {"WRIL",7},  {"HIPR",8}, {"KNER",9},
  //   {"ANKR",10}, {"HIPL",11}, {"KNEL",12}, {"ANKL",13}, {"EYER",14},
  //   {"EYEL",15}, {"EARR",16}, {"EARL",17}};

  // Define the fields that are used to store internal resources
  // Units: positions in mm, covariances in mm², velocities in mm/s, velocity covariances in mm²/s², times in ns
  std::vector<std::vector<Eigen::Vector3d>> _positions; // _positions[j][i] is the position (x,y,z) in mm of the j-th joint of the i-th camera
  std::vector<std::vector<Eigen::Matrix3d>> _covariances;  // _covariances[j][i] is the covariance matrix in mm² of the j-th joint of the i-th camera
  std::vector<std::vector<uint64_t>> _times; // _times[j][i] is the timestamp in ns of the j-th joint of the i-th camera
  std::vector<Eigen::Vector3d> _velocities; // _velocities[j] is the velocity in mm/s of the j-th joint
  std::vector<Eigen::Matrix3d> _velocities_covariances; // _velocities_covariances[j] is the velocity covariance in mm²/s² of the j-th joint
  std::vector<Eigen::Vector3d> _merged_positions; // _merged_positions[j] is the merged position in mm of the j-th joint
  std::vector<Eigen::Matrix3d> _merged_covariances; // _merged_covariances[j] is the merged covariance in mm² of the j-th joint
  uint64_t _last_merge_time; // time of the last merge computation (same for all joints)
  std::vector<int> _camera_used; // is the number of camera used to merge the j-th joint 

  //lists the cameras that are transimitting data
  map<string, int> _cameras; // maps the camera name to its index  if previosly set
};


/*
  ____  _             _             _      _
 |  _ \| |_   _  __ _(_)_ __     __| |_ __(_)_   _____ _ __
 | |_) | | | | |/ _` | | '_ \   / _` | '__| \ \ / / _ \ '__|
 |  __/| | |_| | (_| | | | | | | (_| | |  | |\ V /  __/ |
 |_|   |_|\__,_|\__, |_|_| |_|  \__,_|_|  |_| \_/ \___|_|
                |___/
Enable the class as plugin
*/
INSTALL_FILTER_DRIVER(HpemergerPlugin, json, json);


/*
                  _       
  _ __ ___   __ _(_)_ __  
 | '_ ` _ \ / _` | | '_ \ 
 | | | | | | (_| | | | | |
 |_| |_| |_|\__,_|_|_| |_|
                          
*/

int main(int argc, char const *argv[])
{
  HpemergerPlugin plugin;
  json params;
  json input, output;

  // Set example values to params
  params["test"] = "value";

  // Set the parameters
  plugin.set_params(&params);

  // Set input data
  input["data"] = {
    {"AX", 1},
    {"AY", 2},
    {"AZ", 3}
  };

  // Set input data
  plugin.load_data(input);
  cout << "Input: " << input.dump(2) << endl;

  // Process data
  plugin.process(output);
  cout << "Output: " << output.dump(2) << endl;


  return 0;
}

